{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import accuracy_score\n","\n","url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n","columns = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\n","df = pd.read_csv(url, names=columns)\n","\n","X = df.drop('Outcome', axis=1)\n","y = df['Outcome']\n","\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n","\n","X_train = torch.tensor(X_train, dtype=torch.float32).view(-1, 1, 8)  # Reshape for CNN: (batch_size, channels, features)\n","X_test = torch.tensor(X_test, dtype=torch.float32).view(-1, 1, 8)    # Reshape for CNN: (batch_size, channels, features)\n","y_train = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n","y_test = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)"],"metadata":{"id":"7Gpjho28K7NU","executionInfo":{"status":"ok","timestamp":1733992903481,"user_tz":-480,"elapsed":23651,"user":{"displayName":"IBRAHIM ALSAMANI","userId":"12496900230411675274"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["class CNNModel(nn.Module):\n","    def __init__(self):\n","        super(CNNModel, self).__init__()\n","\n","        # First convolutional layer: Input is (batch_size, 1, 8), output will be (batch_size, 32, 8)\n","        self.conv1 = nn.Conv1d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n","\n","        # Second convolutional layer: Input is (batch_size, 32, 8), output will be (batch_size, 64, 8)\n","        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n","\n","        # Pooling layer: reduce the size of the feature map\n","        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n","\n","        # Fully connected layers after the convolutional layers\n","        self.fc1 = nn.Linear(64 * 4, 128)  # Flattened dimension after pooling\n","        self.fc2 = nn.Linear(128, 1)       # Output layer for binary classification\n","\n","        self.sigmoid = nn.Sigmoid()         # Sigmoid activation for binary classification\n","\n","    def forward(self, x):\n","        # Apply convolution + ReLU activation\n","        x = torch.relu(self.conv1(x))\n","        x = torch.relu(self.conv2(x))\n","\n","        # Pooling layer\n","        x = self.pool(x)\n","\n","        # Flatten the feature map\n","        x = x.view(-1, 64 * 4)  # Flatten the output of the convolutional layers\n","\n","        # Fully connected layers\n","        x = torch.relu(self.fc1(x))\n","        x = self.sigmoid(self.fc2(x))  # Output layer\n","\n","        return x\n"],"metadata":{"id":"OXJAGspdMOIW","executionInfo":{"status":"ok","timestamp":1733992913040,"user_tz":-480,"elapsed":898,"user":{"displayName":"IBRAHIM ALSAMANI","userId":"12496900230411675274"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Initialize the model, loss function, and optimizer\n","model = CNNModel()\n","criterion = nn.BCELoss()  # Binary cross-entropy loss for binary classification\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# Training loop\n","epochs = 1500\n","for epoch in range(epochs):\n","    model.train()  # Set the model to training mode\n","    optimizer.zero_grad()  # Zero the gradients\n","\n","    # Forward pass\n","    output = model(X_train)\n","\n","    # Compute the loss\n","    loss = criterion(output, y_train)\n","\n","    # Backward pass\n","    loss.backward()\n","\n","    # Update the weights\n","    optimizer.step()\n","\n","    if (epoch + 1) % 10 == 0:\n","        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cg_L1n_5MQuD","executionInfo":{"status":"ok","timestamp":1733992958448,"user_tz":-480,"elapsed":42930,"user":{"displayName":"IBRAHIM ALSAMANI","userId":"12496900230411675274"}},"outputId":"794a2774-99f4-42cc-99b1-2aa4d3e1a359"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [10/1500], Loss: 0.5694\n","Epoch [20/1500], Loss: 0.4731\n","Epoch [30/1500], Loss: 0.4515\n","Epoch [40/1500], Loss: 0.4335\n","Epoch [50/1500], Loss: 0.4169\n","Epoch [60/1500], Loss: 0.3998\n","Epoch [70/1500], Loss: 0.3812\n","Epoch [80/1500], Loss: 0.3604\n","Epoch [90/1500], Loss: 0.3405\n","Epoch [100/1500], Loss: 0.3203\n","Epoch [110/1500], Loss: 0.3023\n","Epoch [120/1500], Loss: 0.2832\n","Epoch [130/1500], Loss: 0.2680\n","Epoch [140/1500], Loss: 0.2504\n","Epoch [150/1500], Loss: 0.2324\n","Epoch [160/1500], Loss: 0.2155\n","Epoch [170/1500], Loss: 0.1993\n","Epoch [180/1500], Loss: 0.1821\n","Epoch [190/1500], Loss: 0.1680\n","Epoch [200/1500], Loss: 0.1523\n","Epoch [210/1500], Loss: 0.1361\n","Epoch [220/1500], Loss: 0.1224\n","Epoch [230/1500], Loss: 0.1099\n","Epoch [240/1500], Loss: 0.0980\n","Epoch [250/1500], Loss: 0.0883\n","Epoch [260/1500], Loss: 0.0788\n","Epoch [270/1500], Loss: 0.0704\n","Epoch [280/1500], Loss: 0.0626\n","Epoch [290/1500], Loss: 0.0556\n","Epoch [300/1500], Loss: 0.0489\n","Epoch [310/1500], Loss: 0.0433\n","Epoch [320/1500], Loss: 0.0384\n","Epoch [330/1500], Loss: 0.0341\n","Epoch [340/1500], Loss: 0.0302\n","Epoch [350/1500], Loss: 0.0268\n","Epoch [360/1500], Loss: 0.0239\n","Epoch [370/1500], Loss: 0.0214\n","Epoch [380/1500], Loss: 0.0191\n","Epoch [390/1500], Loss: 0.0171\n","Epoch [400/1500], Loss: 0.0154\n","Epoch [410/1500], Loss: 0.0139\n","Epoch [420/1500], Loss: 0.0125\n","Epoch [430/1500], Loss: 0.0113\n","Epoch [440/1500], Loss: 0.0103\n","Epoch [450/1500], Loss: 0.0094\n","Epoch [460/1500], Loss: 0.0085\n","Epoch [470/1500], Loss: 0.0078\n","Epoch [480/1500], Loss: 0.0072\n","Epoch [490/1500], Loss: 0.0066\n","Epoch [500/1500], Loss: 0.0061\n","Epoch [510/1500], Loss: 0.0056\n","Epoch [520/1500], Loss: 0.0052\n","Epoch [530/1500], Loss: 0.0049\n","Epoch [540/1500], Loss: 0.0046\n","Epoch [550/1500], Loss: 0.0043\n","Epoch [560/1500], Loss: 0.0040\n","Epoch [570/1500], Loss: 0.0037\n","Epoch [580/1500], Loss: 0.0035\n","Epoch [590/1500], Loss: 0.0033\n","Epoch [600/1500], Loss: 0.0031\n","Epoch [610/1500], Loss: 0.0030\n","Epoch [620/1500], Loss: 0.0028\n","Epoch [630/1500], Loss: 0.0027\n","Epoch [640/1500], Loss: 0.0025\n","Epoch [650/1500], Loss: 0.0024\n","Epoch [660/1500], Loss: 0.0023\n","Epoch [670/1500], Loss: 0.0022\n","Epoch [680/1500], Loss: 0.0021\n","Epoch [690/1500], Loss: 0.0020\n","Epoch [700/1500], Loss: 0.0019\n","Epoch [710/1500], Loss: 0.0018\n","Epoch [720/1500], Loss: 0.0017\n","Epoch [730/1500], Loss: 0.0017\n","Epoch [740/1500], Loss: 0.0016\n","Epoch [750/1500], Loss: 0.0015\n","Epoch [760/1500], Loss: 0.0015\n","Epoch [770/1500], Loss: 0.0014\n","Epoch [780/1500], Loss: 0.0014\n","Epoch [790/1500], Loss: 0.0013\n","Epoch [800/1500], Loss: 0.0013\n","Epoch [810/1500], Loss: 0.0012\n","Epoch [820/1500], Loss: 0.0012\n","Epoch [830/1500], Loss: 0.0011\n","Epoch [840/1500], Loss: 0.0011\n","Epoch [850/1500], Loss: 0.0011\n","Epoch [860/1500], Loss: 0.0010\n","Epoch [870/1500], Loss: 0.0010\n","Epoch [880/1500], Loss: 0.0010\n","Epoch [890/1500], Loss: 0.0009\n","Epoch [900/1500], Loss: 0.0009\n","Epoch [910/1500], Loss: 0.0009\n","Epoch [920/1500], Loss: 0.0008\n","Epoch [930/1500], Loss: 0.0008\n","Epoch [940/1500], Loss: 0.0008\n","Epoch [950/1500], Loss: 0.0008\n","Epoch [960/1500], Loss: 0.0008\n","Epoch [970/1500], Loss: 0.0007\n","Epoch [980/1500], Loss: 0.0007\n","Epoch [990/1500], Loss: 0.0007\n","Epoch [1000/1500], Loss: 0.0007\n","Epoch [1010/1500], Loss: 0.0007\n","Epoch [1020/1500], Loss: 0.0006\n","Epoch [1030/1500], Loss: 0.0006\n","Epoch [1040/1500], Loss: 0.0006\n","Epoch [1050/1500], Loss: 0.0006\n","Epoch [1060/1500], Loss: 0.0006\n","Epoch [1070/1500], Loss: 0.0006\n","Epoch [1080/1500], Loss: 0.0005\n","Epoch [1090/1500], Loss: 0.0005\n","Epoch [1100/1500], Loss: 0.0005\n","Epoch [1110/1500], Loss: 0.0005\n","Epoch [1120/1500], Loss: 0.0005\n","Epoch [1130/1500], Loss: 0.0005\n","Epoch [1140/1500], Loss: 0.0005\n","Epoch [1150/1500], Loss: 0.0005\n","Epoch [1160/1500], Loss: 0.0005\n","Epoch [1170/1500], Loss: 0.0004\n","Epoch [1180/1500], Loss: 0.0004\n","Epoch [1190/1500], Loss: 0.0004\n","Epoch [1200/1500], Loss: 0.0004\n","Epoch [1210/1500], Loss: 0.0004\n","Epoch [1220/1500], Loss: 0.0004\n","Epoch [1230/1500], Loss: 0.0004\n","Epoch [1240/1500], Loss: 0.0004\n","Epoch [1250/1500], Loss: 0.0004\n","Epoch [1260/1500], Loss: 0.0004\n","Epoch [1270/1500], Loss: 0.0004\n","Epoch [1280/1500], Loss: 0.0004\n","Epoch [1290/1500], Loss: 0.0003\n","Epoch [1300/1500], Loss: 0.0003\n","Epoch [1310/1500], Loss: 0.0003\n","Epoch [1320/1500], Loss: 0.0003\n","Epoch [1330/1500], Loss: 0.0003\n","Epoch [1340/1500], Loss: 0.0003\n","Epoch [1350/1500], Loss: 0.0003\n","Epoch [1360/1500], Loss: 0.0003\n","Epoch [1370/1500], Loss: 0.0003\n","Epoch [1380/1500], Loss: 0.0003\n","Epoch [1390/1500], Loss: 0.0003\n","Epoch [1400/1500], Loss: 0.0003\n","Epoch [1410/1500], Loss: 0.0003\n","Epoch [1420/1500], Loss: 0.0003\n","Epoch [1430/1500], Loss: 0.0003\n","Epoch [1440/1500], Loss: 0.0003\n","Epoch [1450/1500], Loss: 0.0003\n","Epoch [1460/1500], Loss: 0.0003\n","Epoch [1470/1500], Loss: 0.0002\n","Epoch [1480/1500], Loss: 0.0002\n","Epoch [1490/1500], Loss: 0.0002\n","Epoch [1500/1500], Loss: 0.0002\n"]}]},{"cell_type":"code","source":["# Evaluate the model on the test set\n","model.eval()  # Set the model to evaluation mode\n","with torch.no_grad():  # Disable gradient computation for inference\n","    predictions = model(X_test)\n","    predicted_labels = (predictions > 0.5).float()  # Convert to 0 or 1 based on threshold\n","\n","    # Calculate accuracy\n","    accuracy = accuracy_score(y_test, predicted_labels)\n","    print(f\"Model accuracy on test set: {accuracy * 100:.2f}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XD_I0i1fNjoP","executionInfo":{"status":"ok","timestamp":1733992962282,"user_tz":-480,"elapsed":313,"user":{"displayName":"IBRAHIM ALSAMANI","userId":"12496900230411675274"}},"outputId":"9b1461cd-0049-49cd-cee1-a534f4c6aefe"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Model accuracy on test set: 67.53%\n"]}]}]}