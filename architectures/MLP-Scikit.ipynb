{"cells":[{"cell_type":"markdown","metadata":{"id":"2muLanpaN48w"},"source":["# MLP Classifier for Pima Indians Diabetes Dataset\n","This notebook demonstrates loading the Pima Indians Diabetes dataset, preprocessing, building, training, and evaluating an MLP classifier, as well as optional hyperparameter tuning."],"id":"2muLanpaN48w"},{"cell_type":"code","metadata":{"id":"pp2hrHsZN48y","executionInfo":{"status":"ok","timestamp":1734076732944,"user_tz":-480,"elapsed":7981,"user":{"displayName":"IBRAHIM ALSAMANI","userId":"12496900230411675274"}}},"source":["# Import necessary libraries\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n"],"execution_count":4,"outputs":[],"id":"pp2hrHsZN48y"},{"cell_type":"markdown","metadata":{"id":"Va4_osHvN48y"},"source":["## Define Functions\n","We'll define modular functions for each step."],"id":"Va4_osHvN48y"},{"cell_type":"code","metadata":{"id":"zTz7or_oN48y","executionInfo":{"status":"ok","timestamp":1734076716669,"user_tz":-480,"elapsed":1426,"user":{"displayName":"IBRAHIM ALSAMANI","userId":"12496900230411675274"}}},"source":["def load_data(filepath):\n","    \"\"\"Load the Pima Indians Diabetes dataset from a CSV file.\"\"\"\n","    df = pd.read_csv(filepath)\n","    return df\n","\n","def split_features_target(df, target_col='Outcome'):\n","    \"\"\"Split the DataFrame into features (X) and target (y).\"\"\"\n","    X = df.drop(columns=[target_col])\n","    y = df[target_col]\n","    return X, y\n","\n","def train_test_split_data(X, y, test_size=0.2, random_state=42):\n","    \"\"\"Perform train-test split.\"\"\"\n","    X_train, X_test, y_train, y_test = train_test_split(X, y,\n","                                                        test_size=test_size,\n","                                                        random_state=random_state)\n","    return X_train, X_test, y_train, y_test\n","\n","def scale_features(X_train, X_test):\n","    \"\"\"Scale features using StandardScaler.\"\"\"\n","    scaler = StandardScaler()\n","    X_train_scaled = scaler.fit_transform(X_train)\n","    X_test_scaled = scaler.transform(X_test)\n","    return X_train_scaled, X_test_scaled, scaler\n","\n","def build_mlp(hidden_layer_sizes=(50,50), activation='relu', solver='adam', random_state=42):\n","    \"\"\"Build an MLP classifier with given parameters.\"\"\"\n","    mlp = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes,\n","                        activation=activation,\n","                        solver=solver,\n","                        max_iter=1000,\n","                        random_state=random_state)\n","    return mlp\n","\n","def train_model(model, X_train, y_train):\n","    \"\"\"Train the MLP model.\"\"\"\n","    model.fit(X_train, y_train)\n","    return model\n","\n","def evaluate_model(model, X_test, y_test):\n","    \"\"\"Evaluate the trained model on the test data.\"\"\"\n","    y_pred = model.predict(X_test)\n","    acc = accuracy_score(y_test, y_pred)\n","    print(\"Test Accuracy:\", acc)\n","    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n","    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n","    return acc\n","\n","def tune_mlp(X_train, y_train):\n","    \"\"\"Perform Grid Search to tune MLP hyperparameters.\"\"\"\n","    mlp = MLPClassifier(max_iter=500, random_state=42)\n","    param_grid = {\n","        'hidden_layer_sizes': [(50,), (100,), (50,50)],\n","        'activation': ['tanh', 'relu'],\n","        'solver': ['adam', 'sgd'],\n","        'alpha': [0.0001, 0.001]\n","    }\n","    grid_search = GridSearchCV(mlp, param_grid, cv=3, scoring='accuracy', verbose=1, n_jobs=-1)\n","    grid_search.fit(X_train, y_train)\n","    print(\"Best Parameters:\", grid_search.best_params_)\n","    print(\"Best Score:\", grid_search.best_score_)\n","    return grid_search.best_estimator_\n"],"execution_count":2,"outputs":[],"id":"zTz7or_oN48y"},{"cell_type":"markdown","metadata":{"id":"ghk0A3gDN48z"},"source":["## Load and Preprocess Data\n","Ensure `diabetes.csv` is in the same directory as this notebook."],"id":"ghk0A3gDN48z"},{"cell_type":"markdown","metadata":{"id":"FotGvCsuN48z"},"source":["## Build, Train and Evaluate MLP"],"id":"FotGvCsuN48z"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IRbfxA_IN48z","executionInfo":{"status":"ok","timestamp":1734076733973,"user_tz":-480,"elapsed":657,"user":{"displayName":"IBRAHIM ALSAMANI","userId":"12496900230411675274"}},"outputId":"0c4ffed3-4d81-4458-c01d-7ba26014657b"},"source":["# Load the dataset\n","url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n","columns = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\n","df = ldiabetes_df = pd.read_csv(url, names=columns)\n","X, y = split_features_target(df, target_col='Outcome')\n","X_train, X_test, y_train, y_test = train_test_split_data(X, y, test_size=0.2, random_state=42)\n","X_train_scaled, X_test_scaled, scaler = scale_features(X_train, X_test)\n","print(\"Data loaded and preprocessed.\")"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Data loaded and preprocessed.\n"]}],"id":"IRbfxA_IN48z"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H8wWEw-EN48z","executionInfo":{"status":"ok","timestamp":1734076739923,"user_tz":-480,"elapsed":2832,"user":{"displayName":"IBRAHIM ALSAMANI","userId":"12496900230411675274"}},"outputId":"9c9a6f7d-8b91-4924-8f89-7318770f2577"},"source":["mlp_model = build_mlp(hidden_layer_sizes=(64,64,32), activation='relu', solver='adam')\n","mlp_model = train_model(mlp_model, X_train_scaled, y_train)\n","evaluate_model(mlp_model, X_test_scaled, y_test)"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Accuracy: 0.7077922077922078\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.82      0.70      0.75        99\n","           1       0.57      0.73      0.64        55\n","\n","    accuracy                           0.71       154\n","   macro avg       0.70      0.71      0.70       154\n","weighted avg       0.73      0.71      0.71       154\n","\n","Confusion Matrix:\n"," [[69 30]\n"," [15 40]]\n"]},{"output_type":"execute_result","data":{"text/plain":["0.7077922077922078"]},"metadata":{},"execution_count":6}],"id":"H8wWEw-EN48z"},{"cell_type":"markdown","metadata":{"id":"qApyiqq9N48z"},"source":["## (Optional) Hyperparameter Tuning\n","Uncomment and run the following cell to perform a grid search for better hyperparameters."],"id":"qApyiqq9N48z"},{"cell_type":"code","metadata":{"id":"xZ_y8ypGN48z"},"source":["# best_mlp = tune_mlp(X_train_scaled, y_train)\n","# evaluate_model(best_mlp, X_test_scaled, y_test)"],"execution_count":null,"outputs":[],"id":"xZ_y8ypGN48z"}],"metadata":{"name":"MLP Diabetes Notebook","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}